{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "np.random.seed(0)\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.layers import Input, Embedding, Reshape, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import Flatten, concatenate, Concatenate, Lambda, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.layers import Reshape, MaxPooling1D,BatchNormalization, AveragePooling1D, Conv1D\n",
    "from tensorflow.keras.layers import Activation, LeakyReLU\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Nadam\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2, l1_l2\n",
    "from keras.losses import binary_crossentropy\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "def scaler(scaler, data, test=None):\n",
    "    scaler.fit(data)  # Apply transform to both the training set and the test set.\n",
    "    train_scale = scaler.transform(data)\n",
    "    if test is not None:\n",
    "        test_scale = scaler.fit_transform(test)\n",
    "\n",
    "    return train_scale, test_scale, scaler\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data = pd.read_table('data/dev.tsv')\n",
    "test = pd.read_table('data/eval.tsv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "\n",
    "eval = test.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/anaconda3/envs/ml/lib/python3.8/site-packages/pandas/core/series.py:726: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "def happy_sad(x):\n",
    "    if x>df['valence'].mean():\n",
    "        return 'happy'\n",
    "    else:\n",
    "        return 'sad'\n",
    "\n",
    "def popularity_cat(x):\n",
    "    if x>= 7:\n",
    "        return 'high'\n",
    "    elif x >= 4 and x < 7:\n",
    "        return 'med'\n",
    "    else:\n",
    "        return 'low'\n",
    "\n",
    "df['boringness'] = df['loudness'] + df['tempo'] + (df['energy']*100) + (df['danceability']*100)\n",
    "df['valence_happy_sad'] = df['valence'].apply(lambda x: happy_sad(x))\n",
    "df['loudness_plus_60'] = df['loudness'].apply(lambda x: x+60)\n",
    "df['loudness_pos'] = df['loudness'].apply(lambda x: -1*x)\n",
    "df['loudness_pos'] = np.sqrt(df['loudness_pos'])\n",
    "df['boringness_plus_60'] = df['boringness'].apply(lambda x: x+60)\n",
    "df['duration_ms_box_cox_trans'] = stats.boxcox(df['duration_ms'])[0]\n",
    "df['acousticness_sqrt_trans'] = np.sqrt(df['acousticness'])\n",
    "df['liveness_sqrt_trans'] = np.sqrt(df['liveness'])\n",
    "df['popularity_sqrt_trans'] = np.sqrt(df['popularity'])\n",
    "df['popularity_sqrt_trans_cat'] = df['popularity_sqrt_trans'].apply(lambda x: popularity_cat(x))\n",
    "df['speechiness_sqrt_trans'] = np.sqrt(df['speechiness'])\n",
    "\n",
    "\n",
    "df = df.fillna(value=0)\n",
    "# df.describe().T"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "col = [\n",
    "    'valence',\n",
    "        # 'year',\n",
    "        # 'acousticness',\n",
    "        # 'artists',\n",
    "         'danceability',\n",
    "       'duration_ms',\n",
    "        'energy',\n",
    "        'explicit',\n",
    "        # 'id',\n",
    "        'instrumentalness',\n",
    "        'key',\n",
    "       'liveness',\n",
    "        # 'loudness',\n",
    "        # 'popularity',\n",
    "        # 'speechiness',\n",
    "        'tempo',\n",
    "       #  'mode',\n",
    "       # 'loudness_plus_60',\n",
    "        'loudness_pos',\n",
    "         # 'boringness',\n",
    "       #  'valence_happy_sad',\n",
    "       # 'boringness_plus_60',\n",
    "       #  'duration_ms_box_cox_trans',\n",
    "       'acousticness_sqrt_trans',\n",
    "       #  'liveness_sqrt_trans',\n",
    "       # 'popularity_sqrt_trans',\n",
    "        'speechiness_sqrt_trans',\n",
    "          # 'duration_ms_box_cox_trans_per_class',\n",
    "    # 'popularity_sqrt_trans_cat'\n",
    "        ]\n",
    "\n",
    "X = df[col]\n",
    "y = df['mode']\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler,NearMiss,TomekLinks,ClusterCentroids\n",
    "nm = NearMiss()\n",
    "X_spl, y_spl = nm.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_spl, y_spl,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=0,\n",
    "                                                    shuffle=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "X_train_scal, X_test_scal, x_scaler = scaler(MinMaxScaler(), X_train, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 128)               1664      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 12,673\n",
      "Trainable params: 12,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating the model\n",
    "model = Sequential()\n",
    "\n",
    "# Inputing the first layer with input dimensions\n",
    "model.add(Dense(128,\n",
    "                activation='relu',\n",
    "                input_dim=X_train.shape[1],\n",
    "                kernel_initializer='uniform'))\n",
    "\n",
    "model.add(Dropout(0.50))\n",
    "\n",
    "\n",
    "model.add(Dense(64,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "\n",
    "\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(32,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(16,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(8,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='relu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(1,\n",
    "                kernel_initializer='uniform',\n",
    "                activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average=\"macro\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1226/1226 - 2s - loss: 0.6844 - f1_score: 0.6642 - val_loss: 0.6670 - val_f1_score: 0.6627\n",
      "Epoch 2/30\n",
      "1226/1226 - 2s - loss: 0.6731 - f1_score: 0.6642 - val_loss: 0.6578 - val_f1_score: 0.6627\n",
      "Epoch 3/30\n",
      "1226/1226 - 2s - loss: 0.6684 - f1_score: 0.6642 - val_loss: 0.6495 - val_f1_score: 0.6627\n",
      "Epoch 4/30\n",
      "1226/1226 - 2s - loss: 0.6577 - f1_score: 0.6643 - val_loss: 0.6469 - val_f1_score: 0.6627\n",
      "Epoch 5/30\n",
      "1226/1226 - 2s - loss: 0.6497 - f1_score: 0.6644 - val_loss: 0.6283 - val_f1_score: 0.6628\n",
      "Epoch 6/30\n",
      "1226/1226 - 2s - loss: 0.6477 - f1_score: 0.6646 - val_loss: 0.6300 - val_f1_score: 0.6631\n",
      "Epoch 7/30\n",
      "1226/1226 - 2s - loss: 0.6429 - f1_score: 0.6648 - val_loss: 0.6224 - val_f1_score: 0.6631\n",
      "Epoch 8/30\n",
      "1226/1226 - 2s - loss: 0.6404 - f1_score: 0.6648 - val_loss: 0.6181 - val_f1_score: 0.6632\n",
      "Epoch 9/30\n",
      "1226/1226 - 2s - loss: 0.6414 - f1_score: 0.6649 - val_loss: 0.6207 - val_f1_score: 0.6634\n",
      "Epoch 10/30\n",
      "1226/1226 - 2s - loss: 0.6400 - f1_score: 0.6652 - val_loss: 0.6215 - val_f1_score: 0.6633\n",
      "Epoch 11/30\n",
      "Restoring model weights from the end of the best epoch.\n",
      "1226/1226 - 2s - loss: 0.6402 - f1_score: 0.6651 - val_loss: 0.6138 - val_f1_score: 0.6633\n",
      "Epoch 00011: early stopping\n",
      "751/751 [==============================] - 0s 630us/step - loss: 0.6697 - f1_score: 0.6734\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "f1_score: 67.34%\n"
     ]
    }
   ],
   "source": [
    "#Creating an Stochastic Gradient Descent\n",
    "sgd = SGD(lr = 0.01, momentum = 0.9)\n",
    "\n",
    "# Compiling our model\n",
    "model.compile(optimizer = 'Adam',\n",
    "                   loss = 'binary_crossentropy',\n",
    "                   metrics = [tfa.metrics.F1Score(num_classes=1, average='macro')])\n",
    "#optimizers list\n",
    "#optimizers['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model.fit(X_train_scal, y_train, validation_split=0.3,callbacks=[early_stopping],\n",
    "               batch_size = 32,\n",
    "               epochs = 30, verbose=2)\n",
    "scores = model.evaluate(X_test_scal, y_test, batch_size=32)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation...\n",
      "score is 0.3299377633892439\n"
     ]
    }
   ],
   "source": [
    "print('evaluation...')\n",
    "y_p = model.predict_classes(X_test)\n",
    "y_p =np.squeeze(y_p, axis=1)\n",
    "score = evaluate(y_test, y_p)\n",
    "print(f'score is {score}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omid/anaconda3/envs/ml/lib/python3.8/site-packages/pandas/core/series.py:726: RuntimeWarning: invalid value encountered in sqrt\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def WriteOnFile(name, y_eval):\n",
    "    f = open(name, \"w\")\n",
    "    f.write(\"Id,Predicted\\n\")\n",
    "    for index, i in enumerate(y_eval):\n",
    "        f.write(f\"{index},{i}\\n\")\n",
    "    f.close\n",
    "\n",
    "eval['boringness'] = eval['loudness'] + eval['tempo'] + (eval['energy']*100) + (eval['danceability']*100)\n",
    "eval['valence_happy_sad'] = eval['valence'].apply(lambda x: happy_sad(x))\n",
    "eval['loudness_plus_60'] = eval['loudness'].apply(lambda x: x+60)\n",
    "eval['loudness_pos'] = eval['loudness'].apply(lambda x: -1*x)\n",
    "eval['loudness_pos'] = np.sqrt(eval['loudness_pos'])\n",
    "eval['boringness_plus_60'] = eval['boringness'].apply(lambda x: x+60)\n",
    "eval['duration_ms_box_cox_trans'] = stats.boxcox(eval['duration_ms'])[0]\n",
    "eval['acousticness_sqrt_trans'] = np.sqrt(eval['acousticness'])\n",
    "eval['liveness_sqrt_trans'] = np.sqrt(eval['liveness'])\n",
    "eval['popularity_sqrt_trans'] = np.sqrt(eval['popularity'])\n",
    "eval['speechiness_sqrt_trans'] = np.sqrt(eval['speechiness'])\n",
    "\n",
    "\n",
    "eval = eval.fillna(value=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [],
   "source": [
    "test = eval[col]\n",
    "# test = encoder.transform(test)\n",
    "test_scal = x_scaler.transform(test)\n",
    "test_svd = tsvd.transform(test_scal)\n",
    "y_pred = clf.predict(test_svd)\n",
    "WriteOnFile('submission.csv',y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [
    {
     "data": {
      "text/plain": "       valence  year  danceability  duration_ms  energy  explicit  \\\n0        0.741  1962         0.465       147173   0.389         0   \n1        0.928  1938         0.578       165133   0.234         0   \n2        0.733  1998         0.681       333960   0.726         0   \n3        0.914  2001         0.724       224427   0.731         0   \n4        0.228  2015         0.594       172704   0.850         1   \n...        ...   ...           ...          ...     ...       ...   \n34126    0.783  1965         0.770       155427   0.646         0   \n34127    0.425  1975         0.373       320387   0.423         0   \n34128    0.142  2000         0.156       315267   0.279         0   \n34129    0.844  1982         0.438       225000   0.418         0   \n34130    0.576  1965         0.385       150280   0.341         0   \n\n       instrumentalness  key  liveness    tempo  loudness_pos  \\\n0              0.506000   11    0.1100  125.010      3.843176   \n1              0.000391    0    0.0784  172.403      3.507848   \n2              0.000019    9    0.1190  147.925      2.901896   \n3              0.003430    8    0.1770  101.602      2.675631   \n4              0.000000    2    0.1100  100.002      2.554408   \n...                 ...  ...       ...      ...           ...   \n34126          0.000000    9    0.1370  118.771      3.274599   \n34127          0.527000    0    0.1410  120.941      3.546407   \n34128          0.007810    0    0.1170   72.555      3.179308   \n34129          0.000000    2    0.3300   98.173      3.543445   \n34130          0.000012   10    0.2380  105.755      3.631529   \n\n       acousticness_sqrt_trans  speechiness_sqrt_trans  \n0                     0.997497                0.198746  \n1                     0.958123                0.319374  \n2                     0.356371                0.189209  \n3                     0.391152                0.180278  \n4                     0.170587                0.308869  \n...                        ...                     ...  \n34126                 0.754983                0.261534  \n34127                 0.502991                0.189209  \n34128                 0.979285                0.200000  \n34129                 0.146287                0.198494  \n34130                 0.861974                0.171464  \n\n[34131 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>valence</th>\n      <th>year</th>\n      <th>danceability</th>\n      <th>duration_ms</th>\n      <th>energy</th>\n      <th>explicit</th>\n      <th>instrumentalness</th>\n      <th>key</th>\n      <th>liveness</th>\n      <th>tempo</th>\n      <th>loudness_pos</th>\n      <th>acousticness_sqrt_trans</th>\n      <th>speechiness_sqrt_trans</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.741</td>\n      <td>1962</td>\n      <td>0.465</td>\n      <td>147173</td>\n      <td>0.389</td>\n      <td>0</td>\n      <td>0.506000</td>\n      <td>11</td>\n      <td>0.1100</td>\n      <td>125.010</td>\n      <td>3.843176</td>\n      <td>0.997497</td>\n      <td>0.198746</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.928</td>\n      <td>1938</td>\n      <td>0.578</td>\n      <td>165133</td>\n      <td>0.234</td>\n      <td>0</td>\n      <td>0.000391</td>\n      <td>0</td>\n      <td>0.0784</td>\n      <td>172.403</td>\n      <td>3.507848</td>\n      <td>0.958123</td>\n      <td>0.319374</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.733</td>\n      <td>1998</td>\n      <td>0.681</td>\n      <td>333960</td>\n      <td>0.726</td>\n      <td>0</td>\n      <td>0.000019</td>\n      <td>9</td>\n      <td>0.1190</td>\n      <td>147.925</td>\n      <td>2.901896</td>\n      <td>0.356371</td>\n      <td>0.189209</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.914</td>\n      <td>2001</td>\n      <td>0.724</td>\n      <td>224427</td>\n      <td>0.731</td>\n      <td>0</td>\n      <td>0.003430</td>\n      <td>8</td>\n      <td>0.1770</td>\n      <td>101.602</td>\n      <td>2.675631</td>\n      <td>0.391152</td>\n      <td>0.180278</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.228</td>\n      <td>2015</td>\n      <td>0.594</td>\n      <td>172704</td>\n      <td>0.850</td>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.1100</td>\n      <td>100.002</td>\n      <td>2.554408</td>\n      <td>0.170587</td>\n      <td>0.308869</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>34126</th>\n      <td>0.783</td>\n      <td>1965</td>\n      <td>0.770</td>\n      <td>155427</td>\n      <td>0.646</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>9</td>\n      <td>0.1370</td>\n      <td>118.771</td>\n      <td>3.274599</td>\n      <td>0.754983</td>\n      <td>0.261534</td>\n    </tr>\n    <tr>\n      <th>34127</th>\n      <td>0.425</td>\n      <td>1975</td>\n      <td>0.373</td>\n      <td>320387</td>\n      <td>0.423</td>\n      <td>0</td>\n      <td>0.527000</td>\n      <td>0</td>\n      <td>0.1410</td>\n      <td>120.941</td>\n      <td>3.546407</td>\n      <td>0.502991</td>\n      <td>0.189209</td>\n    </tr>\n    <tr>\n      <th>34128</th>\n      <td>0.142</td>\n      <td>2000</td>\n      <td>0.156</td>\n      <td>315267</td>\n      <td>0.279</td>\n      <td>0</td>\n      <td>0.007810</td>\n      <td>0</td>\n      <td>0.1170</td>\n      <td>72.555</td>\n      <td>3.179308</td>\n      <td>0.979285</td>\n      <td>0.200000</td>\n    </tr>\n    <tr>\n      <th>34129</th>\n      <td>0.844</td>\n      <td>1982</td>\n      <td>0.438</td>\n      <td>225000</td>\n      <td>0.418</td>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>2</td>\n      <td>0.3300</td>\n      <td>98.173</td>\n      <td>3.543445</td>\n      <td>0.146287</td>\n      <td>0.198494</td>\n    </tr>\n    <tr>\n      <th>34130</th>\n      <td>0.576</td>\n      <td>1965</td>\n      <td>0.385</td>\n      <td>150280</td>\n      <td>0.341</td>\n      <td>0</td>\n      <td>0.000012</td>\n      <td>10</td>\n      <td>0.2380</td>\n      <td>105.755</td>\n      <td>3.631529</td>\n      <td>0.861974</td>\n      <td>0.171464</td>\n    </tr>\n  </tbody>\n</table>\n<p>34131 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cols = [\n",
    "#     'valence',\n",
    "#         'year',\n",
    "#         # 'acousticness',\n",
    "#         # 'artists',\n",
    "#          'danceability',\n",
    "#        # 'duration_ms',\n",
    "#         'energy',\n",
    "#         'explicit',\n",
    "#         # 'id',\n",
    "#         'instrumentalness',\n",
    "#         'key',\n",
    "#        'liveness',\n",
    "#         # 'loudness',\n",
    "#         # 'popularity',\n",
    "#         # 'speechiness',\n",
    "#         'tempo',\n",
    "#        #  'mode',\n",
    "#        # 'loudness_plus_60',\n",
    "#         'loudness_pos',\n",
    "#          # 'boringness',\n",
    "#        #  'valence_happy_sad',\n",
    "#        # 'boringness_plus_60',\n",
    "#         'duration_ms_box_cox_trans',\n",
    "#        'acousticness_sqrt_trans',\n",
    "#        #  'liveness_sqrt_trans',\n",
    "#        # 'popularity_sqrt_trans',\n",
    "#         'speechiness_sqrt_trans',\n",
    "#       # 'duration_ms_box_cox_trans_per_class'\n",
    "#         ]\n",
    "n/metrics/_classification.py:1043 f1_score  *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}